{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating Novel View Synthesis Models\n",
    "\n",
    "In this notebook, we show how to obtain metrics for a given trained novel view synthesis model.\n",
    "\n",
    "We evaluate the metrics as follows:\n",
    "- We calculate `PSNR`, `SSIM`, and `LPIPS` metrics for all images separately. These metrics values are averaged over all images in a given scene.\n",
    "- The `FID` metric is calculated over all predicted / ground-truth images in one scene in one sweep.\n",
    "- To obtain the final metrics for the full dataset, we average the metrics over all scenes. Every scene is weighted with the same weight."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Model rediction directory structure\n",
    "\n",
    "We assume the rendered images from your model to have the same directory structure as the downloaded scenes.\n",
    "\n",
    "If an image to be evaluated has the location\n",
    "\n",
    "```bash\n",
    "/path/to/wayve_scenes_101/<scene_name>/images/<camera>/<imname>.jpeg\n",
    "```\n",
    "\n",
    "We expect the location of the respective predicted image to be in \n",
    "\n",
    "```bash\n",
    "/path/to/your/predictions/<scene_name>/images/<camera>/<imname>.jpeg\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation on full dataset\n",
    "\n",
    "In the following, we show how to run our evaluation suite on the full WayveScenes101 dataset.\n",
    "\n",
    "We generate nested dictionaries of metrics, breaking down the metrics per image, per scene, and on the full dataset. We generate separate metrics for:\n",
    "- The train split of each scene (cameras: `left-forward`, `right-forward`, `left-backward`, `right-backward`)\n",
    "- The test split (`front-forward` camera)\n",
    "- All cameras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from wayve_scenes.evaluation import evaluate_submission\n",
    "\n",
    "\n",
    "# Replace the location of the directories with the location the dataset and your predictions on your machine\n",
    "dir_target = '/path/to/wayve_scenes_101/'\n",
    "dir_pred = '/path/to/model_predictions/'\n",
    "\n",
    "# Perform the evaluation\n",
    "metrics_dict_all, metrics_dict_train, metrics_dict_test = evaluate_submission(dir_pred, dir_target)\n",
    "\n",
    "# Print the final metrics\n",
    "print(json.dumps(metrics_dict_all, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation on specific scenes\n",
    "\n",
    "With the WayveScenes101 scene metadata, we can also perform analysis of our model performance on specific subsets of scenes. \n",
    "\n",
    "In the example below, we obtain the metrics for the scene `scene_002`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_all, metrics_train, metrics_test = evaluate_submission(dir_pred, dir_target, scene_list=[\"scene_002\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation on scenes with specific properties\n",
    "\n",
    "We can also use the scene metadata file to select a specific subset of scenes for evaluation. In the example below, we will obtain the metrics for nighttime scenes and compare it with the performance for daytime scenes.\n",
    "\n",
    "> Note: In this example, we use the `scene_metadata.csv` to select scenes to evaluate. Thus, we assume that all dataset scenes are downloaded and extracted in the `wayve_scenes_101` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "# Load the metadata dataframe\n",
    "scenes_df = pd.read_csv(\"../data/scene_metadata.csv\")\n",
    "\n",
    "# get the scenes with a specific environmental condition\n",
    "scenes_df_daytime = scenes_df[scenes_df[\"Time of Day\"] == \"Day\"]\n",
    "scenes_df_nighttime = scenes_df[scenes_df[\"Time of Day\"] == \"Night\"]\n",
    "\n",
    "metrics_daytime_all, metrics_daytime_train, metrics_daytime_test = evaluate_submission(dir_pred, dir_target, scene_list=scenes_df_daytime[\"scene_id\"].values)\n",
    "metrics_nighttime_all, metrics_nighttime_train, metrics_nighttime_test = evaluate_submission(dir_pred, dir_target, scene_list=scenes_df_daytime[\"scene_id\"].values)\n",
    "\n",
    "print(\"Daytime metrics test split: \")\n",
    "print(json.dumps(metrics_daytime_test, indent=4))\n",
    "\n",
    "print(\"Nighttime metrics test split: \")\n",
    "print(json.dumps(metrics_nighttime_test, indent=4))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
